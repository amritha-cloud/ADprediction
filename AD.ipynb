{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HerXShutLYsg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOpYE-c2L25d",
        "outputId": "3a07af5d-9d06-4c0b-a1d4-283daf12a796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GiLM02usL_5j"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
        "from keras.activations import sigmoid\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import initializers\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJQG-6DvLgXL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wFzpMsbeNAXT"
      },
      "outputs": [],
      "source": [
        "#train path\n",
        "train_p = \"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\"\n",
        "#test path\n",
        "test_p = \"/content/drive/MyDrive/Alzheimer_s Dataset-2/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7-I6xBAqNN3i"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.1,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = train_datagen.flow_from_directory(directory=train_p, \n",
        "                                                  classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                           'MildDemented', 'ModerateDemented'], \n",
        "                                                  target_size=(224, 224),\n",
        "                                                  subset='training', \n",
        "                                                  batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXREALXGp3DB",
        "outputId": "9148a021-d46c-4b6e-ed20-3f8f614361b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4610 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_batches = train_datagen.flow_from_directory(directory=train_p, \n",
        "                                                       classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                                'MildDemented', 'ModerateDemented'], \n",
        "                                                       target_size=(224, 224),\n",
        "                                                       subset='validation',\n",
        "                                                       batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns7_C-pap7I-",
        "outputId": "87dccfe1-13a6-443b-ed59-e8928eeb4e28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 511 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "HoQiT-iep-3d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batches = test_datagen.flow_from_directory(directory=test_p, \n",
        "                                                classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                         'MildDemented', 'ModerateDemented'], \n",
        "                                                target_size=(224, 224),\n",
        "                                                batch_size=10, \n",
        "                                                shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2zAozLPqJm6",
        "outputId": "811ddca1-5ee7-41e0-a7d0-952e381ee849"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1279 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I added data augmentation to the training data generator, which includes rescaling, shearing, zooming, and horizontal flipping of the images. I also specified the target_size parameter to resize the images to a common size of 224 x 224 pixels, which is a commonly used size for image classification models.\n",
        "\n",
        "I also separated the training data generator and the test data generator to have different parameters. For the test data generator, I only included rescaling to normalize the pixel values.\n",
        "\n",
        "Overall, these changes should improve the performance of the machine learning model by augmenting the training data and resizing the images to a common size."
      ],
      "metadata": {
        "id": "TMmZ1Ekeqm42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tWhYNR2tNVGX"
      },
      "outputs": [],
      "source": [
        "class_names = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
        "num_images = []\n",
        "\n",
        "for cls in class_names:\n",
        "    path = os.path.join(train_p, cls)\n",
        "    num_images.append(len(os.listdir(path)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.bar(class_names, num_images, color=(0.1, 0.2, 0.4, 0.9))\n",
        "ax.set_title('Number of Images per Class')\n",
        "ax.set_xlabel('Class')\n",
        "ax.set_ylabel('Number of Images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "S5U9AeC2qSIY",
        "outputId": "5c98b6cd-3e40-442f-d6ff-702fcf6a066a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of Images')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I renamed the data dictionary to num_images to better reflect the information it stores. I also used os.path.join() to construct the path to the image directories, which is more platform-independent.\n",
        "\n",
        "Instead of using two loops to iterate through each class and each image in the training data, I simply looped through the class_names list and used os.listdir() to count the number of images in each class directory. The resulting counts are stored in the num_images list.\n",
        "\n",
        "Finally, I used the subplots() function to create a figure with a single subplot, and passed the ax object to the bar() function to plot the data. I also added a title, and x and y axis labels to the plot for clarity."
      ],
      "metadata": {
        "id": "BQznm9boqvpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NiViTPHCNZlf"
      },
      "outputs": [],
      "source": [
        "img_size = 224\n",
        "num_classes = 4\n",
        "model = Sequential([\n",
        "    layers.Input((img_size, img_size, 3)),\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(300, activation='relu'),\n",
        "    layers.Dense(150, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ocasbTAXNVRP"
      },
      "outputs": [],
      "source": [
        "metrics = [keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           keras.metrics.AUC(name='auc')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4Z2G-2izNewt"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hChS3ujUNhdf"
      },
      "outputs": [],
      "source": [
        "epo = 5\n",
        "b_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XN3j5-kyNlZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dfb5c1-16ae-4ebe-9b38-0124afc087c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "461/461 - 810s - loss: 1.3232 - accuracy: 0.4757 - precision: 0.5079 - recall: 0.3883 - auc: 0.7607 - val_loss: 5.7273 - val_accuracy: 0.0098 - val_precision: 0.0098 - val_recall: 0.0098 - val_auc: 0.4143 - 810s/epoch - 2s/step\n",
            "Epoch 2/5\n",
            "461/461 - 68s - loss: 0.9950 - accuracy: 0.5174 - precision: 0.6234 - recall: 0.3742 - auc: 0.8148 - val_loss: 0.9726 - val_accuracy: 0.5421 - val_precision: 0.6527 - val_recall: 0.3973 - val_auc: 0.8232 - 68s/epoch - 147ms/step\n",
            "Epoch 3/5\n",
            "461/461 - 70s - loss: 0.9645 - accuracy: 0.5347 - precision: 0.6391 - recall: 0.3748 - auc: 0.8214 - val_loss: 0.9020 - val_accuracy: 0.5558 - val_precision: 0.6980 - val_recall: 0.3346 - val_auc: 0.8436 - 70s/epoch - 152ms/step\n",
            "Epoch 4/5\n",
            "461/461 - 68s - loss: 0.9203 - accuracy: 0.5447 - precision: 0.6412 - recall: 0.3831 - auc: 0.8355 - val_loss: 0.8787 - val_accuracy: 0.5362 - val_precision: 0.6269 - val_recall: 0.4012 - val_auc: 0.8514 - 68s/epoch - 147ms/step\n",
            "Epoch 5/5\n",
            "461/461 - 67s - loss: 0.9121 - accuracy: 0.5588 - precision: 0.6537 - recall: 0.3967 - auc: 0.8413 - val_loss: 0.9041 - val_accuracy: 0.5460 - val_precision: 0.6667 - val_recall: 0.3679 - val_auc: 0.8427 - 67s/epoch - 146ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x=train_batches,\n",
        "                    validation_data=validation_batches,\n",
        "                    steps_per_epoch=len(train_batches),\n",
        "                    validation_steps=len(validation_batches),\n",
        "                    epochs=epo,\n",
        "                    batch_size=b_size, \n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = '/content/drive/MyDrive/Alzheimer_s Dataset-2/test/MildDemented/26 (19).jpg'\n",
        "img = image.load_img(img_path, target_size=(img_size, img_size))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "class_names = train_datagen\n",
        "for name, idx in class_names():\n",
        "    if idx == class_idx:\n",
        "        print(\"Predicted class: \", name, \"with probability of: \", preds[0][idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "UV-XlfK-0Gwv",
        "outputId": "f315fa8d-d8d3-460f-ffb2-fc9651bb8f6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b88e38a0cc21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted class: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with probability of: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ImageDataGenerator' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jEPVkqBgcwhP"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}