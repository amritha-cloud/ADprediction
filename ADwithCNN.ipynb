{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HerXShutLYsg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOpYE-c2L25d"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiLM02usL_5j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import random \n",
        "import cv2\n",
        "import keras\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
        "from keras.activations import sigmoid\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import initializers\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFzpMsbeNAXT"
      },
      "outputs": [],
      "source": [
        "#train path\n",
        "train_p = \"/content/drive/MyDrive/Alzheimer_s Dataset/train\"\n",
        "#test path\n",
        "test_p = \"/content/drive/MyDrive/Alzheimer_s Dataset/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-I6xBAqNN3i"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.1,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXREALXGp3DB"
      },
      "outputs": [],
      "source": [
        "train_batches = train_datagen.flow_from_directory(directory=train_p, \n",
        "                                                  classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                           'MildDemented', 'ModerateDemented'], \n",
        "                                                  target_size=(224, 224),\n",
        "                                                  subset='training', \n",
        "                                                  batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns7_C-pap7I-"
      },
      "outputs": [],
      "source": [
        "validation_batches = train_datagen.flow_from_directory(directory=train_p, \n",
        "                                                       classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                                'MildDemented', 'ModerateDemented'], \n",
        "                                                       target_size=(224, 224),\n",
        "                                                       subset='validation',\n",
        "                                                       batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoQiT-iep-3d"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2zAozLPqJm6"
      },
      "outputs": [],
      "source": [
        "test_batches = test_datagen.flow_from_directory(directory=test_p, \n",
        "                                                classes=['NonDemented', 'VeryMildDemented', \n",
        "                                                         'MildDemented', 'ModerateDemented'], \n",
        "                                                target_size=(224, 224),\n",
        "                                                batch_size=10, \n",
        "                                                shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMmZ1Ekeqm42"
      },
      "source": [
        "I added data augmentation to the training data generator, which includes rescaling, shearing, zooming, and horizontal flipping of the images. I also specified the target_size parameter to resize the images to a common size of 224 x 224 pixels, which is a commonly used size for image classification models.\n",
        "\n",
        "I also separated the training data generator and the test data generator to have different parameters. For the test data generator, I only included rescaling to normalize the pixel values.\n",
        "\n",
        "Overall, these changes should improve the performance of the machine learning model by augmenting the training data and resizing the images to a common size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWhYNR2tNVGX"
      },
      "outputs": [],
      "source": [
        "class_names = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']\n",
        "num_images = []\n",
        "\n",
        "for cls in class_names:\n",
        "    path = os.path.join(train_p, cls)\n",
        "    num_images.append(len(os.listdir(path)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5U9AeC2qSIY"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.bar(class_names, num_images, color=(0.7, 0.2, 0.4, 0.9))\n",
        "ax.set_title('Number of Images per Class')\n",
        "ax.set_xlabel('Class')\n",
        "ax.set_ylabel('Number of Images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQznm9boqvpE"
      },
      "source": [
        "I renamed the data dictionary to num_images to better reflect the information it stores. I also used os.path.join() to construct the path to the image directories, which is more platform-independent.\n",
        "\n",
        "Instead of using two loops to iterate through each class and each image in the training data, I simply looped through the class_names list and used os.listdir() to count the number of images in each class directory. The resulting counts are stored in the num_images list.\n",
        "\n",
        "Finally, I used the subplots() function to create a figure with a single subplot, and passed the ax object to the bar() function to plot the data. I also added a title, and x and y axis labels to the plot for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiViTPHCNZlf"
      },
      "outputs": [],
      "source": [
        "img_size = 224\n",
        "num_classes = 4\n",
        "model = Sequential([\n",
        "    layers.Input((img_size, img_size, 3)),\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(300, activation='relu'),\n",
        "    layers.Dense(150, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocasbTAXNVRP"
      },
      "outputs": [],
      "source": [
        "metrics = [keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           keras.metrics.AUC(name='auc')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z2G-2izNewt"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hChS3ujUNhdf"
      },
      "outputs": [],
      "source": [
        "epo = 5\n",
        "b_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN3j5-kyNlZb"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=train_batches,\n",
        "                    validation_data=validation_batches,\n",
        "                    steps_per_epoch=len(train_batches),\n",
        "                    validation_steps=len(validation_batches),\n",
        "                    epochs=epo,\n",
        "                    batch_size=b_size, \n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAM:\n",
        "    def __init__(self, model, classIdx, layerName=None):\n",
        "        self.model = model\n",
        "        self.classIdx = classIdx\n",
        "        self.layerName = layerName\n",
        "\n",
        "        if self.layerName is None:\n",
        "            self.layerName = self.find_target_layer()\n",
        "            \n",
        "    def find_target_layer(self):\n",
        "        for layer in reversed(self.model.layers):\n",
        "            if len(layer.output_shape) == 4:\n",
        "                return layer.name\n",
        "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "        \n",
        "    def compute_heatmap(self, image, eps=1e-8):\n",
        "\n",
        "        gradModel = tf.keras.Model(\n",
        "        inputs=[self.model.inputs],\n",
        "        outputs=[self.model.get_layer(self.layerName).output,\n",
        "                 self.model.output])\n",
        "      \n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            inputs = tf.cast(image, tf.float32)\n",
        "            (convOutputs, predictions) = gradModel(inputs)\n",
        "            loss = predictions[:, self.classIdx]\n",
        "        \n",
        "\n",
        "        grads = tape.gradient(loss, convOutputs)\n",
        "\n",
        "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "        castGrads = tf.cast(grads > 0, \"float32\")\n",
        "        guidedGrads = castConvOutputs * castGrads * grads\n",
        "        \n",
        "      \n",
        "        convOutputs = convOutputs[0]\n",
        "        guidedGrads = guidedGrads[0]\n",
        "        \n",
        "\n",
        "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "\n",
        "        (w, h) = (image.shape[2], image.shape[1])\n",
        "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "    \n",
        "        numer = heatmap - np.min(heatmap)\n",
        "        denom = (heatmap.max() - heatmap.min()) + eps\n",
        "        heatmap = numer / denom\n",
        "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "\n",
        "        return heatmap\n",
        "\n",
        "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
        "        colormap=cv2.COLORMAP_VIRIDIS):\n",
        "\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "        image = np.asarray(image, np.float64)\n",
        "        heatmap = np.asarray(heatmap, np.float64)\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "\n",
        "        return (heatmap, output)"
      ],
      "metadata": {
        "id": "UALDJLa60GDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_heatmap(model, img_path):\n",
        "    image = load_img(img_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    preds = model.predict(image)\n",
        "    i = np.argmax(preds[0])\n",
        "    label_to_class = {'NonDemented': 0,\n",
        "                      'VeryMildDemented': 1,\n",
        "                      'MildDemented': 2,\n",
        "                      'ModerateDemented': 3}\n",
        "\n",
        "    class_to_label = {v: k for k, v in label_to_class.items()}\n",
        "\n",
        "    label = class_to_label[i]\n",
        "    print(f'Predicted class: {label} | Prediction probability: {max(preds[0]) * 100}%')\n",
        "    \n",
        "    cam = GradCAM(model, i)\n",
        "    heatmap = cam.compute_heatmap(image)\n",
        "\n",
        "    (heatmap, output) = cam.overlay_heatmap(heatmap, image[0], alpha=0.5)\n",
        "    \n",
        "    output = output.astype(np.uint8)\n",
        "    plt.imshow(output, interpolation='nearest')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xfgVBVXl0L8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "iYvzs12R0Ws-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ],
      "metadata": {
        "id": "UmqnCCsm0ZM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/Alzheimer_s Dataset/test/NonDemented/26 (64).jpg\"\n",
        "show_heatmap(model,img_path)"
      ],
      "metadata": {
        "id": "o7tKcyAu0Otu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}