{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7cHvsZI3X24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import tensorflow \n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "gnQX9GGG3jnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wabegr8a3lvp",
        "outputId": "a437f2df-4e9f-461e-bc21-aec449e11957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16 ,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/test\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16 ,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvN3V5RQ3eLv",
        "outputId": "83b9a3bd-6644-4309-adc6-626d5677c320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 files belonging to 4 classes.\n",
            "Using 4097 files for training.\n",
            "Found 5121 files belonging to 4 classes.\n",
            "Using 1024 files for validation.\n",
            "Found 1279 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classname = train_ds.class_names\n",
        "len(classname),train_ds.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5VHsZG3-iC",
        "outputId": "0eff722a-77a6-4a69-e2d7-0710af4f7e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "IMG_SIZE = 180\n",
        "IMAGE_SIZE = [180, 180]\n",
        "DIM = (IMG_SIZE, IMG_SIZE)\n",
        "ZOOM = [.99, 1.01]\n",
        "BRIGHT_RANGE = [0.8, 1.2]\n",
        "HORZ_FLIP = True\n",
        "FILL_MODE = \"constant\"\n",
        "DATA_FORMAT = \"channels_last\"\n",
        "WORK_DIR=\"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\"\n",
        "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
        "\n",
        "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0WsTdvk4Y7S",
        "outputId": "a73dd1b2-16d7-4f6c-d50d-2dcb317a081e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "inception_model = InceptionV3(input_shape=(180, 180, 3), include_top=False, weights=\"imagenet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uai0kZEP-EFa",
        "outputId": "56c578f9-d279-46bb-c047-16dd48097b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inception_model.layers:\n",
        "    layer.trainable=False"
      ],
      "metadata": {
        "id": "Ci7jWcb5_RCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n",
        "custom_inception_model = Sequential([\n",
        "        inception_model,\n",
        "        Dropout(0.5),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Flatten(),\n",
        "        BatchNormalization(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        BatchNormalization(),\n",
        "        Dense(4, activation='softmax')        \n",
        "    ], name = \"inception_cnn_model\")"
      ],
      "metadata": {
        "id": "9TeX7Ktw_UG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('acc') > 0.99:\n",
        "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
        "            self.model.stop_training = True\n",
        "            \n",
        "my_callback = MyCallback()\n",
        "\n",
        "#ReduceLROnPlateau to stabilize the training process of the model\n",
        "rop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=3)"
      ],
      "metadata": {
        "id": "mBjP5_yT_XY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
        "           tf.keras.metrics.AUC(name='auc')]\n",
        "\n",
        "CALLBACKS = [my_callback, rop_callback]\n",
        "    \n",
        "custom_inception_model.compile(optimizer='rmsprop',\n",
        "                              loss=tf.losses.CategoricalCrossentropy(),\n",
        "                              metrics=METRICS)"
      ],
      "metadata": {
        "id": "h3FpY7yu_aZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the training data to the model and validate it using the validation data\n",
        "EPOCHS = 20\n",
        "\n",
        "history = custom_inception_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "koy_zSWGrFUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['acc', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "id": "EaCEqpPnrKKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = custom_inception_model.evaluate(test_data, test_labels)\n",
        "\n",
        "#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
        "#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\n",
        "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
      ],
      "metadata": {
        "id": "TTDduLTsrPUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}