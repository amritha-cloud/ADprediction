{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w7cHvsZI3X24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import tensorflow \n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "gnQX9GGG3jnb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wabegr8a3lvp",
        "outputId": "a437f2df-4e9f-461e-bc21-aec449e11957"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16 ,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Alzheimer_s Dataset-2/test\",\n",
        "    seed=1337,\n",
        "    image_size=[180, 180],\n",
        "    batch_size=16 ,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvN3V5RQ3eLv",
        "outputId": "83b9a3bd-6644-4309-adc6-626d5677c320"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 files belonging to 4 classes.\n",
            "Using 4097 files for training.\n",
            "Found 5121 files belonging to 4 classes.\n",
            "Using 1024 files for validation.\n",
            "Found 1279 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classname = train_ds.class_names\n",
        "len(classname),train_ds.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5VHsZG3-iC",
        "outputId": "0eff722a-77a6-4a69-e2d7-0710af4f7e7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "IMG_SIZE = 180\n",
        "IMAGE_SIZE = [180, 180]\n",
        "DIM = (IMG_SIZE, IMG_SIZE)\n",
        "ZOOM = [.99, 1.01]\n",
        "BRIGHT_RANGE = [0.8, 1.2]\n",
        "HORZ_FLIP = True\n",
        "FILL_MODE = \"constant\"\n",
        "DATA_FORMAT = \"channels_last\"\n",
        "WORK_DIR=\"/content/drive/MyDrive/Alzheimer_s Dataset-2/train\"\n",
        "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
        "\n",
        "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0WsTdvk4Y7S",
        "outputId": "a73dd1b2-16d7-4f6c-d50d-2dcb317a081e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5121 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "inception_model = InceptionV3(input_shape=(180, 180, 3), include_top=False, weights=\"imagenet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uai0kZEP-EFa",
        "outputId": "56c578f9-d279-46bb-c047-16dd48097b4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inception_model.layers:\n",
        "    layer.trainable=False"
      ],
      "metadata": {
        "id": "Ci7jWcb5_RCR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n",
        "custom_inception_model = Sequential([\n",
        "        inception_model,\n",
        "        Dropout(0.5),\n",
        "        GlobalAveragePooling2D(),\n",
        "        Flatten(),\n",
        "        BatchNormalization(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        BatchNormalization(),\n",
        "        Dense(4, activation='softmax')        \n",
        "    ], name = \"inception_cnn_model\")"
      ],
      "metadata": {
        "id": "9TeX7Ktw_UG1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('acc') > 0.99:\n",
        "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
        "            self.model.stop_training = True\n",
        "            \n",
        "my_callback = MyCallback()\n",
        "\n",
        "#ReduceLROnPlateau to stabilize the training process of the model\n",
        "rop_callback = ReduceLROnPlateau(monitor=\"val_loss\", patience=3)"
      ],
      "metadata": {
        "id": "mBjP5_yT_XY-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
        "           tf.keras.metrics.AUC(name='auc')]\n",
        "\n",
        "CALLBACKS = [my_callback, rop_callback]\n",
        "    \n",
        "custom_inception_model.compile(optimizer='rmsprop',\n",
        "                              loss=tf.losses.CategoricalCrossentropy(),\n",
        "                              metrics=METRICS)"
      ],
      "metadata": {
        "id": "h3FpY7yu_aZJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['acc', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "NlS-fNKv_dWu",
        "outputId": "862d6a2c-ed0e-462d-8204-1b134a27c9f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b10527a904fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}